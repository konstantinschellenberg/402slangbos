dfAll <- rbind(dfAll, df)
}
# subsetting
nsamples <- 1000
sdfAll <- dfAll[sample(1:nrow(dfAll), nsamples), ]
# train model
modFit_rf <- train(as.factor(class) ~ X2015.03.11 + X2015.03.18 + X2015.03.23 + X2015.03.30 + X2015.04.04 + X2015.04.11 +
X2015.04.11 + X2015.04.16 + X2015.04.23 + X2015.04.28 + X2015.05.05, method = "glm", data = sdfAll)
beginCluster()
system.time(preds_rf <- clusterR(raster, raster::predict, args = list(model = modFit_rf)))
endCluster()
raster::writeRaster(preds_rf, "D:\\Geodaten\\#Jupiter\\GEO402\\04_products\\rf\\preds_rf_20200111_vh_sample10_3_NA")
beginCluster()
raster[raster == -99] = NA
endCluster()
#subsetting raster
raster = raster[[1:20]]
raster
beginCluster()
raster[raster == -99] = NA
endCluster()
raster
plot(raster)
# set crs(roi) to the crs(s1) brick. Remove Z-Dimension
trainData_sf =  st_read(training_path) %>%
st_transform(st_crs(raster)) %>%
st_zm(drop = TRUE)
trainData = as(trainData_sf, Class = "Spatial")
responseCol = "Name"
# Extracting training pixel values
# creating new df to fit pixel extraction
# credits to http://amsantac.co/blog/en/2015/11/28/classification-r.html
dfAll = data.frame(matrix(vector(), nrow = 0, ncol = length(names(raster)) + 1))
for (i in 1:length(unique(trainData[[responseCol]]))){
category <- unique(trainData[[responseCol]])[i]
categorymap <- trainData[trainData[[responseCol]] == category,]
dataSet <- extract(raster, categorymap)
dataSet <- dataSet[!unlist(lapply(dataSet, is.null))]
dataSet <- lapply(dataSet, function(x){cbind(x, class = as.numeric(rep(category, nrow(x))))})
df <- do.call("rbind", dataSet)
dfAll <- rbind(dfAll, df)
}
# subsetting
nsamples <- 1000
sdfAll <- dfAll[sample(1:nrow(dfAll), nsamples), ]
# train model
modFit_rf <- train(as.factor(class) ~ X2015.03.11 + X2015.03.18 + X2015.03.23 + X2015.03.30 + X2015.04.04 + X2015.04.11 +
X2015.04.11 + X2015.04.16 + X2015.04.23 + X2015.04.28 + X2015.05.05, method = "glm", data = sdfAll)
beginCluster()
system.time(preds_rf <- clusterR(raster, raster::predict, args = list(model = modFit_rf)))
endCluster()
raster::writeRaster(preds_rf, "D:\\Geodaten\\#Jupiter\\GEO402\\04_products\\rf\\preds_rf_20200111_vh_sample10_3_NA")
# set crs(roi) to the crs(s1) brick. Remove Z-Dimension
trainData_sf =  st_read(training_path) %>%
st_transform(st_crs(raster)) %>%
st_zm(drop = TRUE)
trainData = as(trainData_sf, Class = "Spatial")
responseCol = "Name"
# Extracting training pixel values
# creating new df to fit pixel extraction
# credits to http://amsantac.co/blog/en/2015/11/28/classification-r.html
dfAll = data.frame(matrix(vector(), nrow = 0, ncol = length(names(raster)) + 1))
for (i in 1:length(unique(trainData[[responseCol]]))){
category <- unique(trainData[[responseCol]])[i]
categorymap <- trainData[trainData[[responseCol]] == category,]
dataSet <- extract(raster, categorymap)
dataSet <- dataSet[!unlist(lapply(dataSet, is.null))]
dataSet <- lapply(dataSet, function(x){cbind(x, class = as.numeric(rep(category, nrow(x))))})
df <- do.call("rbind", dataSet)
dfAll <- rbind(dfAll, df)
}
# subsetting
nsamples <- 1000
sdfAll <- dfAll[sample(1:nrow(dfAll), nsamples), ]
# train model
modFit_rf <- train(as.factor(class) ~ X2015.03.11 + X2015.03.18 + X2015.03.23 + X2015.03.30 + X2015.04.04 + X2015.04.11 +
X2015.04.11 + X2015.04.16 + X2015.04.23 + X2015.04.28 + X2015.05.05, method = "rf", data = sdfAll)
beginCluster()
system.time(preds_rf <- clusterR(raster, raster::predict, args = list(model = modFit_rf)))
endCluster()
raster::writeRaster(preds_rf, "D:\\Geodaten\\#Jupiter\\GEO402\\04_products\\rf\\preds_rf_20200111_vh_sample10_3_NA", overwrite=TRUE)
plot(raster)
names(raster)
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster[[-1]]
raster
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_[[-14, -17]]
raster_ = rename_bandnames(raster = s1vh)
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_[[-14, -17]]
raster = raster[1:30]
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_[[-14, -17]]
raster = raster[[1:30]]
raster
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_[[-14, -17]]
raster = raster[[1:30]]
raster
plot(raster)
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_[[-14, -16]]
raster = raster[[1:30]]
plot(raster)
raster_rename = rename_bandnames(raster = s1vh)
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_rename[[-14, -16]]
raster
names(raster)
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_rename[[-14, -16]]
names(raster)
length(names(raster))
length(names(raster_rename))
names(raster)
raster = raster[[1:30]]
raster
names(raster)
plot(raster_rename[[1:30]])
plot(raster_rename[[14]])
plot(raster_rename[[17]])
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_rename[[-(14, 17)]]
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_rename[[-(14 17)]]
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_rename[c(-14, -17)]
raster
length(names(raster))
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_rename[c(-14, -17)]
raster
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster_rename[[c(-14, -17)]]
length(names(raster))
names(raster)
plot(raster)
raster = rename_bandnames(raster = s1vh) %>%
.[[c(-14, -17, -62)]]
raster
plot(raster[[1:20]])
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster[[1:30]]
names(raster)
# set crs(roi) to the crs(s1) brick. Remove Z-Dimension
trainData_sf =  st_read(training_path) %>%
st_transform(st_crs(raster)) %>%
st_zm(drop = TRUE)
trainData = as(trainData_sf, Class = "Spatial")
responseCol = "Name"
# Extracting training pixel values
# creating new df to fit pixel extraction
# credits to http://amsantac.co/blog/en/2015/11/28/classification-r.html
dfAll = data.frame(matrix(vector(), nrow = 0, ncol = length(names(raster)) + 1))
for (i in 1:length(unique(trainData[[responseCol]]))){
category <- unique(trainData[[responseCol]])[i]
categorymap <- trainData[trainData[[responseCol]] == category,]
dataSet <- extract(raster, categorymap)
dataSet <- dataSet[!unlist(lapply(dataSet, is.null))]
dataSet <- lapply(dataSet, function(x){cbind(x, class = as.numeric(rep(category, nrow(x))))})
df <- do.call("rbind", dataSet)
dfAll <- rbind(dfAll, df)
}
# subsetting
nsamples <- 1000
sdfAll <- dfAll[sample(1:nrow(dfAll), nsamples), ]
nsamples <- 1000
sdfAll <- dfAll[sample(1:nrow(dfAll), nsamples), ]
# train model
modFit_rf <- train(as.factor(class) ~ ., method = "rf", data = sdfAll)
# predict model
beginCluster()
system.time(preds_rf <- clusterR(raster, raster::predict, args = list(model = modFit_rf)))
endCluster()
# write as file
raster::writeRaster(preds_rf, "D:\\Geodaten\\#Jupiter\\GEO402\\04_products\\rf\\preds_rf_20200111_vh_sample30_rm.NA.tif", overwrite=TRUE)
for (i in 1:length(unique(trainData[[responseCol]]))){
category <- unique(trainData[[responseCol]])[i]
categorymap <- trainData[trainData[[responseCol]] == category,]
dataSet <- extract(raster, categorymap)
dataSet <- dataSet[!unlist(lapply(dataSet, is.null))]
dataSet <- lapply(dataSet, function(x){cbind(x, class = as.numeric(rep(category, nrow(x))))})
df <- do.call("rbind", dataSet)
dfAll <- rbind(dfAll, df)
}
# watch the video for introduction in RF for remote sensing
# https://www.youtube.com/watch?v=fal4Jj81uMA
# for tuning
# https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/
# ------------------------------------------------------------------------------
library(sf)
library(rgdal)
library(raster)
library(caret)
# ------------------------------------------------------------------------------
training_path = "D:\\Geodaten\\#Jupiter\\GEO402\\02_features\\ROI_updated.kml"
s1vv_path = "D:\\Geodaten\\#Jupiter\\GEO402\\01_data\\s1_data\\S1_A_D_VV_free_state_study_area_geo402"
s1vh_path = "D:\\Geodaten\\#Jupiter\\GEO402\\01_data\\s1_data\\S1_A_D_VH_free_state_study_area_geo402"
# import raster
s1vv = brick(s1vv_path)
s1vh = brick(s1vh_path)
names(s1vv)
# Renaming------------------------------------------------------------------------------
rename_bandnames = function(raster = s1vv){
bandnames = names(raster)
# iterate for date in column-names
for (i in bandnames){
date_in_bandnames = substr(bandnames,13,20)
}
# convert date string into R date-time format
date <- c()
for (i in 1:length(date_in_bandnames)){
date <- append(date, as.POSIXct(date_in_bandnames[i], format = "%Y%m%d")) #https://www.statmethods.net/input/dates.html
}
names(raster) <- paste0(date) # change names to more easy
return(raster)
}
# remove data with little coverage of the region of interest
raster = rename_bandnames(raster = s1vh) %>%
.[[c(-14, -17, -62)]]
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster[[1:30]]
plot(raster)
# beginCluster()
# raster[raster == -99] = NA
# endCluster()
# Read in training data-----------------------------------------------------------
# set crs(roi) to the crs(s1) brick. Remove Z-Dimension
trainData_sf =  st_read(training_path) %>%
st_transform(st_crs(raster)) %>%
st_zm(drop = TRUE)
trainData = as(trainData_sf, Class = "Spatial")
responseCol = "Name"
# Extracting training pixel values
# creating new df to fit pixel extraction
# credits to http://amsantac.co/blog/en/2015/11/28/classification-r.html
dfAll = data.frame(matrix(vector(), nrow = 0, ncol = length(names(raster)) + 1))
trainData
for (i in 1:length(unique(trainData[[responseCol]]))){
category <- unique(trainData[[responseCol]])[i]
categorymap <- trainData[trainData[[responseCol]] == category,]
dataSet <- extract(raster, categorymap)
dataSet <- dataSet[!unlist(lapply(dataSet, is.null))]
dataSet <- lapply(dataSet, function(x){cbind(x, class = as.numeric(rep(category, nrow(x))))})
df <- do.call("rbind", dataSet)
dfAll <- rbind(dfAll, df)
}
# subsetting
nsamples <- 1000
sdfAll <- dfAll[sample(1:nrow(dfAll), nsamples), ]
# train model
modFit_rf <- train(as.factor(class) ~ ., method = "rf", data = sdfAll)
# predict model
beginCluster()
system.time(preds_rf <- clusterR(raster, raster::predict, args = list(model = modFit_rf)))
endCluster()
# write as file
raster::writeRaster(preds_rf, "D:\\Geodaten\\#Jupiter\\GEO402\\04_products\\rf\\preds_rf_20200111_vh_sample30_rm.NA.tif", overwrite=TRUE)
View(s1vh)
View(sdfAll)
nsamples <- 1000
sdfAll <- dfAll[sample(1:nrow(dfAll), nsamples), ]
# train model
modFit_rf <- train(as.factor(class) ~ ., method = "rf", data = sdfAll)
# predict model
beginCluster()
system.time(preds_rf <- clusterR(raster, raster::predict, args = list(model = modFit_rf)))
endCluster()
View(categorymap)
# write as file
raster::writeRaster(preds_rf, "D:\\Geodaten\\#Jupiter\\GEO402\\04_products\\rf\\preds_rf_20200111_vh_sample30_rm.NA.tif", overwrite=TRUE)
sdfAll["class"]
summary(sdfAll["class"])
nsamples <- 1000
sdfAll <- dfAll[sample(1:nrow(dfAll), nsamples), ]
summary(sdfAll["class"])
sdfAll["class"]
modFit_rf
trainData
summary(trainData)
# s1_vv_summaries
vv = list_summaries(sentinel1_brick = s1vv,
polygon = roi)
source("import_parse.R")
# s1_vv_summaries
vv = list_summaries(sentinel1_brick = s1vv,
polygon = roi)
# s1_vh_summaries
vh = list_summaries(sentinel1_brick = s1vh,
polygon = roi)
install.packages("tinytex")
tinytex::install_tinytex()  # install TinyTeX
install.packages("tinytex")
tinytex::install_tinytex()  # install TinyTeX
tinytex:::is_tinytex()
knit_with_parameters('D:/Geodaten/Master/projects/402slangbos/slangbos_encroachment.Rmd')
install.packages(tufte)
install.packages("tufte")
if (!require("remotes")) install.packages("remotes", repos = "http://cran.rstudio.org")
remotes::install_github("rstudio/bookdown")
if (!require("remotes")) install.packages("remotes", repos = "http://cran.rstudio.org")
remotes::install_github("rstudio/bookdown")
remotes::install_github("ismayc/thesisdown")
remove.packages("igest")
remove.packages("digest")
install.packages("digest")
if (!require("remotes")) install.packages("remotes", repos = "http://cran.rstudio.org")
remotes::install_github("rstudio/bookdown")
remotes::install_github("ismayc/thesisdown")
install.packages("rlang"
)
install.packages("rlang")
remotes::install_github("ismayc/thesisdown")
remove.packages("curl")
install.packages("curl")
remotes::install_github("ismayc/thesisdown")
my.packages = c("raster", "sf", "rgdal", "caret")
lapply(my.packages, require, character.only = TRUE)
knitr::write_bib(my.packages,
file = "refs.bib",
prefix = "R-"
)
knitr::write_bib(my.packages,
file = "refs.bib",
prefix = "R-"
)
my.packages
c("bookdown", "knitr", "osmdata", "rgrass7", "sf", "dplyr", "TSP", "jsonlite", "base", "tidyverse", "dplyr")
# Chunk 1
my.packages = c("raster", "sf", "rgdal", "caret")
lapply(my.packages, require, character.only = TRUE)
knitr::write_bib(my.packages,
file = "refs.bib",
prefix = "R-"
)
install.packages("cast")
install.packages("CAST")
vignette(cast)
vignette("cast")
??CAST
library(CAST)
library("CAST")
data <- get(load(system.file("extdata","Cookfarm.RData",package="CAST")))
head(data)
names(data)
plot(data)
names(data)
plot(data)
plot(data[["sourceid"]])
plot(data[["SOURCEID"]])
library(lubridate)
library(ggplot2)
trainDat <- data[data$altitude==-0.3&
year(data$Date)==2012&
week(data$Date)%in%c(13:14),]
ggplot(data = trainDat, aes(x=Date, y=VW)) +
geom_line(aes(colour=SOURCEID))
View(trainDat)
library(caret)
predictors <- c("DEM","BLD","TWI","Precip_cum","cday",
"MaxT_wrcc","Precip_wrcc",
"Northing","Easting","NDRE.M")
set.seed(10)
model <- train(trainDat[,predictors],trainDat$VW,
method="rf",tuneLength=1,importance=TRUE,
trControl=trainControl(method="cv",number=5))
# watch the video for introduction in RF for remote sensing
# https://www.youtube.com/watch?v=fal4Jj81uMA
# for tuning
# https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/
# ------------------------------------------------------------------------------
library(sf)
library(rgdal)
library(raster)
library(caret)
# ------------------------------------------------------------------------------
training_path = "D:\\Geodaten\\#Jupiter\\GEO402\\02_features\\ROI_updated.kml"
s1vv_path = "D:\\Geodaten\\#Jupiter\\GEO402\\01_data\\s1_data\\S1_A_D_VV_free_state_study_area_geo402"
s1vh_path = "D:\\Geodaten\\#Jupiter\\GEO402\\01_data\\s1_data\\S1_A_D_VH_free_state_study_area_geo402"
# import raster
s1vv = brick(s1vv_path)
s1vh = brick(s1vh_path)
names(s1vv)
# Renaming------------------------------------------------------------------------------
rename_bandnames = function(raster = s1vv){
bandnames = names(raster)
# iterate for date in column-names
for (i in bandnames){
date_in_bandnames = substr(bandnames,13,20)
}
# convert date string into R date-time format
date <- c()
for (i in 1:length(date_in_bandnames)){
date <- append(date, as.POSIXct(date_in_bandnames[i], format = "%Y%m%d")) #https://www.statmethods.net/input/dates.html
}
names(raster) <- paste0(date) # change names to more easy
return(raster)
}
# remove data with little coverage of the region of interest
raster = rename_bandnames(raster = s1vh) %>%
.[[c(-14, -17, -62)]]
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster[[1:30]]
# beginCluster()
# raster[raster == -99] = NA
# endCluster()
# Read in training data-----------------------------------------------------------
# set crs(roi) to the crs(s1) brick. Remove Z-Dimension
trainData_sf =  st_read(training_path) %>%
st_transform(st_crs(raster)) %>%
st_zm(drop = TRUE)
trainData = as(trainData_sf, Class = "Spatial")
responseCol = "Name"
# Extracting training pixel values
# creating new df to fit pixel extraction
# credits to http://amsantac.co/blog/en/2015/11/28/classification-r.html
dfAll = data.frame(matrix(vector(), nrow = 0, ncol = length(names(raster)) + 1))
for (i in 1:length(unique(trainData[[responseCol]]))){
category <- unique(trainData[[responseCol]])[i]
categorymap <- trainData[trainData[[responseCol]] == category,]
dataSet <- extract(raster, categorymap)
dataSet <- dataSet[!unlist(lapply(dataSet, is.null))]
dataSet <- lapply(dataSet, function(x){cbind(x, class = as.numeric(rep(category, nrow(x))))})
df <- do.call("rbind", dataSet)
dfAll <- rbind(dfAll, df)
}
# subsetting
nsamples <- 1000
sdfAll <- dfAll[sample(1:nrow(dfAll), nsamples), ]
# watch the video for introduction in RF for remote sensing
# https://www.youtube.com/watch?v=fal4Jj81uMA
# for tuning
# https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/
# ------------------------------------------------------------------------------
library(sf)
library(rgdal)
library(raster)
library(caret)
# ------------------------------------------------------------------------------
training_path = "D:\\Geodaten\\#Jupiter\\GEO402\\02_features\\ROI_updated.kml"
s1vv_path = "D:\\Geodaten\\#Jupiter\\GEO402\\01_data\\s1_data\\S1_A_D_VV_free_state_study_area_geo402"
s1vh_path = "D:\\Geodaten\\#Jupiter\\GEO402\\01_data\\s1_data\\S1_A_D_VH_free_state_study_area_geo402"
# import raster
s1vv = brick(s1vv_path)
s1vh = brick(s1vh_path)
names(s1vv)
# Renaming------------------------------------------------------------------------------
rename_bandnames = function(raster = s1vv){
bandnames = names(raster)
# iterate for date in column-names
for (i in bandnames){
date_in_bandnames = substr(bandnames,13,20)
}
# convert date string into R date-time format
date <- c()
for (i in 1:length(date_in_bandnames)){
date <- append(date, as.POSIXct(date_in_bandnames[i], format = "%Y%m%d")) #https://www.statmethods.net/input/dates.html
}
names(raster) <- paste0(date) # change names to more easy
return(raster)
}
# remove data with little coverage of the region of interest
raster = rename_bandnames(raster = s1vh) %>%
.[[c(-14, -17, -62)]]
#subsetting raster for easier calculation. Max. variables for rf is 32
raster = raster[[1:10]]
# beginCluster()
# raster[raster == -99] = NA
# endCluster()
# Read in training data-----------------------------------------------------------
# set crs(roi) to the crs(s1) brick. Remove Z-Dimension
trainData_sf =  st_read(training_path) %>%
st_transform(st_crs(raster)) %>%
st_zm(drop = TRUE)
trainData = as(trainData_sf, Class = "Spatial")
responseCol = "Name"
# Extracting training pixel values
# creating new df to fit pixel extraction
# credits to http://amsantac.co/blog/en/2015/11/28/classification-r.html
dfAll = data.frame(matrix(vector(), nrow = 0, ncol = length(names(raster)) + 1))
for (i in 1:length(unique(trainData[[responseCol]]))){
category <- unique(trainData[[responseCol]])[i]
categorymap <- trainData[trainData[[responseCol]] == category,]
dataSet <- extract(raster, categorymap)
dataSet <- dataSet[!unlist(lapply(dataSet, is.null))]
dataSet <- lapply(dataSet, function(x){cbind(x, class = as.numeric(rep(category, nrow(x))))})
df <- do.call("rbind", dataSet)
dfAll <- rbind(dfAll, df)
}
# subsetting
nsamples <- 1000
sdfAll <- dfAll[sample(1:nrow(dfAll), nsamples), ]
sdfAll
trainData
summary(trainDat)
summary(trainData)
summary(trainDat)
modFit_rf <- train(as.factor(class) ~ ., method = "rf", data = sdfAll,
s
modFit_rf <- train(as.factor(class) ~ ., method = "rf", data = sdfAll,
importance=TRUE,
trControl=trainControl(method="cv",number=5))
trainControl()
modFit_rf
beginCluster()
system.time(preds_rf <- clusterR(raster, raster::predict, args = list(model = modFit_rf)))
endCluster()
# write as file
raster::writeRaster(preds_rf, "D:\\Geodaten\\#Jupiter\\GEO402\\04_products\\rf\\preds_rf_20200112_vh_sample10_CV.tif", overwrite=TRUE)
CAST
??CAST
